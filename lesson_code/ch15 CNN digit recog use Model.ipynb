{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "vQ9rZ9-qfSzt",
   "metadata": {
    "id": "vQ9rZ9-qfSzt"
   },
   "source": [
    "# ใช้งาน TensorFlow Model - บน Anacona\n",
    "load model filename:  <b>digitmodel.h5</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dbb805-9679-4649-8c5e-bdaea528cf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('digitmodel.h5')    # Load model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6907de48-a190-4823-942d-c2d6f12214da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel for Convo Only!\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model_layer_idx = 2\n",
    "\n",
    "kernels, biases = model.layers[model_layer_idx].get_weights()\n",
    "print(kernels.shape)\n",
    "\n",
    "kernel_idx = 0                ##  0 1 2 3 ...\n",
    "kernel_i = kernels[:, :, 0 , kernel_idx]\n",
    "print(kernel_i.round(2))\n",
    "\n",
    "plt.imshow(kernel_i, cmap=plt.cm.gray) \n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f8fa56-1238-4e59-b583-fc8020cd03b4",
   "metadata": {},
   "source": [
    "## Read Image and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e4e24e-b248-4b0e-9977-fb87bc984ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.image import rgb_to_grayscale\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "filename = 'data/digit2-1.png'          # Digit image to predict\n",
    "# filename = 'data/digit4-1.png'\n",
    "\n",
    "img = load_img(filename, target_size=(28, 28))\n",
    "display(img)\n",
    "img = ImageOps.invert(img)      # invert\n",
    "img = img_to_array(img)\n",
    "img = rgb_to_grayscale(img)\n",
    "\n",
    "print('img shape:', img.shape)\n",
    "print('max pixel value:',np.max(img))\n",
    "\n",
    "img /= 255.0            # Normalize\n",
    "\n",
    "img = np.expand_dims(img, axis=0)\n",
    "print('Expandim:', img.shape)\n",
    "\n",
    "y_pred = model.predict(img)\n",
    "print(y_pred.round(3))\n",
    "\n",
    "predicted = np.argmax(y_pred, -1)\n",
    "# predicted = np.argmax(y_pred, axis=1)\n",
    "print('\\nPredicted Number=', predicted[0])\n",
    "\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.imshow(img[0].reshape(28,28), cmap=plt.cm.gray_r)\n",
    "plt.title('Predicted:{}'. format(predicted[0]))\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83921876-639d-47ac-881d-921c57d79c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Code\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.image import rgb_to_grayscale\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "filename = 'data/digit2-1.png'          # Digit image to predict\n",
    "filename = 'data/digit4-1.png'\n",
    "\n",
    "img = load_img(filename, target_size=(28, 28))\n",
    "display(img)\n",
    "img = ImageOps.invert(img)      # invert\n",
    "img = img_to_array(img)\n",
    "img = rgb_to_grayscale(img)\n",
    "\n",
    "img /= 255.0            # Normalize\n",
    "img = np.expand_dims(img, axis=0)\n",
    "\n",
    "y_pred = model.predict(img)\n",
    "\n",
    "predicted = np.argmax(y_pred, -1)\n",
    "# predicted = np.argmax(y_pred, axis=1)\n",
    "print('\\nPredicted Number=', predicted[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a5f920-7a12-4e83-a46e-756f1213a3a2",
   "metadata": {},
   "source": [
    "## Feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbac076-7fe5-47ed-b527-9da9c8c55afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "model_layer_idx = 2           # model layer id (0=first layer)\n",
    "md = Model(inputs=model.inputs, outputs=model.layers[model_layer_idx].output)\n",
    "\n",
    "feature_maps = md.predict(img)\n",
    "feature_maps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e917f6-0f77-420b-866f-ae47563fb49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = 0      # sample id\n",
    "fea_idx = 0        # index of Feature Map \n",
    "feature_map_i = feature_maps[sample_idx, :, :, fea_idx]\n",
    "\n",
    "plt.title(f'Feature Map: {feature_map_i.shape[0]}x{feature_map_i.shape[0]}')\n",
    "plt.imshow(feature_map_i, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0628a44a-2052-4172-b643-49660c7c035a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nplots = 30\n",
    "layername = model.layers[model_layer_idx].name\n",
    "\n",
    "fig = plt.figure(figsize=(12, 10)) \n",
    "fig.suptitle(f'Feature Map: Layer {model_layer_idx}  {layername} \\\n",
    "   {feature_map_i.shape[0]}x{feature_map_i.shape[0]}',\n",
    "             fontsize=14)\n",
    "\n",
    "for j in range(nplots):\n",
    "    plt.subplot(6, 5, j+1)\n",
    "    plt.imshow(feature_maps[sample_idx, :, :, j], cmap=plt.cm.gray)\n",
    "    plt.title(j)\n",
    "    plt.xticks([]) # ; plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-wnLLRYwONA7",
   "metadata": {
    "id": "-wnLLRYwONA7"
   },
   "source": [
    "# ใช้ TensorFlow Model - บน Colab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bF41j5n0ZTXn",
   "metadata": {
    "id": "bF41j5n0ZTXn"
   },
   "outputs": [],
   "source": [
    "# Colab\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "!ls '/content/drive/MyDrive/Colab Notebooks/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e300983c-7431-4438-86e5-75e3dffd09b1",
   "metadata": {
    "id": "e300983c-7431-4438-86e5-75e3dffd09b1"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "gpath = '/content/drive/MyDrive/Colab Notebooks/'\n",
    "\n",
    "model = load_model(gpath + 'digitmodel.h5') \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aJddKLAVEz67",
   "metadata": {
    "id": "aJddKLAVEz67"
   },
   "source": [
    "## Upload a digit image to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1R8s4i9kES9l",
   "metadata": {
    "id": "1R8s4i9kES9l"
   },
   "outputs": [],
   "source": [
    "# Upload\n",
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "filename = next(iter(uploaded))\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nd9848XMEaCh",
   "metadata": {
    "id": "nd9848XMEaCh"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.image import rgb_to_grayscale\n",
    "\n",
    "gpath = '/content/drive/MyDrive/Colab Notebooks/'\n",
    "\n",
    "img = load_img(filename, target_size=(28, 28))\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "n3qCj0VPf-_Y",
   "metadata": {
    "id": "n3qCj0VPf-_Y"
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "\n",
    "img = load_img(filename, target_size=(28, 28))\n",
    "\n",
    "img = ImageOps.invert(img)\n",
    "img = img_to_array(img)\n",
    "img = rgb_to_grayscale(img)\n",
    "\n",
    "print('shape=',img.shape)\n",
    "# print('max pixel value=',np.max(img))\n",
    "\n",
    "img /= 255.0\n",
    "\n",
    "img = np.expand_dims(img, axis=0)\n",
    "img.shape\n",
    "\n",
    "y_pred = model.predict(img)\n",
    "\n",
    "predicted = np.argmax(y_pred, -1) \n",
    "\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.imshow(img[0].reshape(28,28), cmap=plt.cm.gray_r)\n",
    "plt.title('Predicted:{}'. format(predicted[0]))\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e65a6f-c301-4cd0-b089-3794aced18ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4511cf0f-1502-4b72-af3d-e0ccd6105338",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "CNN digits use Model.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
